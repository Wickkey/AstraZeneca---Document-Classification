{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import pandas as pd\n",
    "import docx.document\n",
    "import docx.oxml.table\n",
    "import docx.oxml.text.paragraph\n",
    "import docx.table\n",
    "import docx.text.paragraph\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data for doc and docx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = Document('../data/input-word-document.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_paragraphs(parent, recursive=True):\n",
    "    \"\"\"\n",
    "    Yield each paragraph and table child within *parent*, in document order.\n",
    "    Each returned value is an instance of Paragraph. *parent*\n",
    "    would most commonly be a reference to a main Document object, but\n",
    "    also works for a _Cell object, which itself can contain paragraphs and tables.\n",
    "    \"\"\"\n",
    "    if isinstance(parent, docx.document.Document):\n",
    "        parent_elm = parent.element.body\n",
    "    elif isinstance(parent, docx.table._Cell):\n",
    "        parent_elm = parent._tc\n",
    "    else:\n",
    "        raise TypeError(repr(type(parent)))\n",
    "\n",
    "    for child in parent_elm.iterchildren():\n",
    "        if isinstance(child, docx.oxml.text.paragraph.CT_P):\n",
    "            yield docx.text.paragraph.Paragraph(child, parent)\n",
    "        elif isinstance(child, docx.oxml.table.CT_Tbl):\n",
    "            if recursive:\n",
    "                table = docx.table.Table(child, parent)\n",
    "                yield table\n",
    "        else:\n",
    "            print(child)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CT_SectPr '<w:sectPr>' at 0x1a616a87d18>\n"
     ]
    }
   ],
   "source": [
    "document = Document('output-word-document.docx')\n",
    "df = pd.DataFrame(columns=['Text', 'Contains Image', 'Contains Table'])\n",
    "for paragraph in iter_paragraphs(document):\n",
    "    image = 0\n",
    "    table = 0\n",
    "    if isinstance(paragraph, docx.text.paragraph.Paragraph):\n",
    "        text = paragraph.text\n",
    "        if 'graphicData' in paragraph._p.xml:\n",
    "            image = 1\n",
    "    elif isinstance(paragraph, docx.table.Table):\n",
    "        table = 1\n",
    "        text = \"\"\n",
    "        for row in paragraph.rows:\n",
    "            for cell in row.cells:\n",
    "                temp = cell.text\n",
    "                temp = temp.replace('\\n', '')\n",
    "                text += temp\n",
    "\n",
    "    df = df.append({'Text': text, 'Contains Image': image,\n",
    "                    'Contains Table': table}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting information\n",
    "startreg = [r\"<<START_HEADING>>.*\",\n",
    "            r\"<<START_SUBHEADING>>.*\", r\"<<START_SECTION>>.*\"]\n",
    "endreg = [r\".*<<END_HEADING>>\", r\".*<<END_SUBHEADING>>\", r\".*<<END_SECTION>>\"]\n",
    "\n",
    "\n",
    "def complete_tags(df):\n",
    "    prev_startTag = None\n",
    "    prev_endTag = None\n",
    "    for index, row in df.iterrows():\n",
    "        curr_startTag = None\n",
    "        curr_endTag = None\n",
    "        for regex_start, regex_end in zip(startreg, endreg):\n",
    "            if re.compile(regex_start).match(row['text']):\n",
    "                curr_startTag = regex_start[:-2]  # to account for .*\n",
    "            if re.compile(regex_end).match(row['text']):\n",
    "                curr_endTag = regex_end[2:]  # to account for .*\n",
    "\n",
    "\n",
    "        if curr_startTag == None and curr_endTag == None:\n",
    "            if prev_startTag == None and prev_endTag == None:\n",
    "                # do nothing\n",
    "                df.loc[index, 'extracted_text'] = df.loc[index, 'text']\n",
    "            elif prev_startTag and prev_endTag == None:\n",
    "                curr_startTag = prev_startTag\n",
    "                curr_endTag = prev_endTag\n",
    "                df.loc[index, 'text'] = curr_startTag + row['text'] + \\\n",
    "                    endreg[startreg.index(curr_startTag+r'.*')][2:]\n",
    "                regex = curr_startTag + \\\n",
    "                    r\"(?P<text>.*)\" + \\\n",
    "                    endreg[startreg.index(curr_startTag+r'.*')][2:]\n",
    "                pattern = re.compile(regex)\n",
    "                try:\n",
    "                    extract_text = pattern.search(\n",
    "                        df.loc[index, 'text']).group(1)\n",
    "                except:\n",
    "                    print(row['text'])\n",
    "                    break\n",
    "                df.loc[index, 'extracted_text'] = extract_text\n",
    "                df.loc[index, 'class'] = startreg.index(curr_startTag+r'.*')\n",
    "\n",
    "        elif curr_startTag and curr_endTag:\n",
    "            regex = curr_startTag + r\"(?P<text>.*)\" + curr_endTag\n",
    "            pattern = re.compile(regex)\n",
    "            try:\n",
    "                extract_text = pattern.search(df.loc[index, 'text']).group(1)\n",
    "            except:\n",
    "                print(row['text'])\n",
    "                break\n",
    "            df.loc[index, 'extracted_text'] = extract_text\n",
    "            df.loc[index, 'class'] = startreg.index(curr_startTag+r'.*')\n",
    "            curr_startTag = None\n",
    "            curr_endTag = None\n",
    "\n",
    "        elif curr_startTag and curr_endTag == None:\n",
    "            df.loc[index, 'text'] = row['text'] + \\\n",
    "                endreg[startreg.index(curr_startTag+r'.*')][2:]\n",
    "            regex = curr_startTag + \\\n",
    "                r\"(?P<text>.*)\" + \\\n",
    "                endreg[startreg.index(curr_startTag+r'.*')][2:]\n",
    "            pattern = re.compile(regex)\n",
    "            try:\n",
    "                extract_text = pattern.search(df.loc[index, 'text']).group(1)\n",
    "            except:\n",
    "                print(row['text'])\n",
    "                break\n",
    "            df.loc[index, 'extracted_text'] = extract_text\n",
    "            df.loc[index, 'class'] = startreg.index(curr_startTag+r'.*')\n",
    "\n",
    "        elif curr_startTag == None and curr_endTag:\n",
    "            df.loc[index, 'text'] = startreg[endreg.index(\n",
    "                r'.*'+curr_endTag)][:-2] + row['text']\n",
    "            regex = startreg[endreg.index(\n",
    "                r'.*'+curr_endTag)][:-2] + r\"(?P<text>.*)\" + curr_endTag\n",
    "            pattern = re.compile(regex)\n",
    "            try:\n",
    "                extract_text = pattern.search(df.loc[index, 'text']).group(1)\n",
    "            except:\n",
    "                print(row['text'])\n",
    "                break\n",
    "            df.loc[index, 'extracted_text'] = extract_text\n",
    "            df.loc[index, 'class'] = endreg.index(r'.*'+curr_endTag)\n",
    "            curr_startTag = None\n",
    "            curr_endTag = None\n",
    "\n",
    "        prev_startTag = curr_startTag\n",
    "        prev_endTag = curr_endTag\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2.columns = ['text', 'contains_image', 'contains_table']\n",
    "df2 = df2.reindex(columns=['text', 'contains_image',\n",
    "                           'contains_table', 'extracted_text', 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>contains_image</th>\n",
       "      <th>contains_table</th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>â–¼This medicinal product is subject to addit...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>â–¼This medicinal product is subject to addit...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;&lt;START_HEADING&gt;&gt;AUSTRALIAN PRODUCT INFORMATIO...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AUSTRALIAN PRODUCT INFORMATION</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;&lt;START_SUBHEADING&gt;&gt;IMFINZIÂ®&lt;&lt;END_SUBHEADING&gt;&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IMFINZIÂ®</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;&lt;START_SUBHEADING&gt;&gt; (durvalumab) &lt;&lt;END_SUBHEA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(durvalumab)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>&lt;&lt;START_SECTION&gt;&gt;Summary table of changes &lt;&lt;EN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary table of changes</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>&lt;&lt;START_SECTION&gt;&gt;Section changed Summary of ne...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Section changed Summary of new information 4.1...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>&lt;&lt;START_SECTION&gt;&gt;Â© AstraZeneca 2021 &lt;&lt;END_SECT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Â© AstraZeneca 2021</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>&lt;&lt;START_SECTION&gt;&gt; Doc ID-003924983 v14 &lt;&lt;END_S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Doc ID-003924983 v14</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>477 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text contains_image  \\\n",
       "0       â–¼This medicinal product is subject to addit...              0   \n",
       "1    <<START_HEADING>>AUSTRALIAN PRODUCT INFORMATIO...              0   \n",
       "2      <<START_SUBHEADING>>IMFINZIÂ®<<END_SUBHEADING>>               0   \n",
       "3                                                                   0   \n",
       "4    <<START_SUBHEADING>> (durvalumab) <<END_SUBHEA...              0   \n",
       "..                                                 ...            ...   \n",
       "472  <<START_SECTION>>Summary table of changes <<EN...              0   \n",
       "473  <<START_SECTION>>Section changed Summary of ne...              0   \n",
       "474  <<START_SECTION>>Â© AstraZeneca 2021 <<END_SECT...              0   \n",
       "475  <<START_SECTION>> Doc ID-003924983 v14 <<END_S...              0   \n",
       "476                                                                 0   \n",
       "\n",
       "    contains_table                                     extracted_text  class  \n",
       "0                0     â–¼This medicinal product is subject to addit...    NaN  \n",
       "1                0                     AUSTRALIAN PRODUCT INFORMATION    0.0  \n",
       "2                0                                           IMFINZIÂ®    1.0  \n",
       "3                0                                                       NaN  \n",
       "4                0                                      (durvalumab)     1.0  \n",
       "..             ...                                                ...    ...  \n",
       "472              0                          Summary table of changes     2.0  \n",
       "473              1  Section changed Summary of new information 4.1...    2.0  \n",
       "474              0                                Â© AstraZeneca 2021     2.0  \n",
       "475              0                              Doc ID-003924983 v14     2.0  \n",
       "476              0                                                       NaN  \n",
       "\n",
       "[477 rows x 5 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_tags(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(df,drop_section = True):\n",
    "    df_new = df[['extracted_text', 'class',\n",
    "                 'contains_image', 'contains_table']]\n",
    "    df_new.dropna(axis=0, subset=['class'], inplace=True)\n",
    "    df_new['extracted_text'] = df_new['extracted_text'].str.strip()\n",
    "    df_new = df_new[(df_new['extracted_text'] != '') |\n",
    "                    (df_new['contains_image'] != 0)]\n",
    "    df_new.reset_index(drop=True, inplace=True)\n",
    "    df_new['extracted_text'] = df_new['extracted_text'].astype(str)\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    df_new['words'] = df_new['extracted_text'].apply(lambda x: len(x.split()))\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df_new['stopwords'] = df_new['extracted_text'].apply(\n",
    "        lambda x: len(set(x.split()) & stop_words))\n",
    "    df_new['endswithdot'] = df_new['extracted_text'].str.endswith('.')\n",
    "    df_new['endswithdot'] = df_new['endswithdot'].astype(int)\n",
    "    df_new['Table'] = df_new['extracted_text'].str.contains('Table')\n",
    "    df_new['Table'] = df_new['Table'].astype(int)\n",
    "    df_new['contains section'] = df_new['extracted_text'].str.contains(\n",
    "        'Section')\n",
    "    df_new['contains section'] = df_new['contains section'].astype(int)\n",
    "    df_new['contains percentage'] = df_new['extracted_text'].str.contains('%')\n",
    "    df_new['contains percentage'] = df_new['contains percentage'].astype(int)\n",
    "    df_new['Uppercase'] = df_new['extracted_text'].str.findall(\n",
    "        r'[A-Z]').str.len()\n",
    "    df_new['Lowercase'] = df_new['extracted_text'].str.findall(\n",
    "        r'[a-z]').str.len()\n",
    "    df_new['percentage capital'] = (\n",
    "        df_new['Uppercase']*100)/(df_new['Lowercase']+df_new['Uppercase'])\n",
    "    if drop_section:\n",
    "        df_new.drop(columns=['Uppercase', 'Lowercase','contains section'], inplace=True)\n",
    "    else:\n",
    "        df_new.drop(columns=['Uppercase', 'Lowercase'], inplace=True)\n",
    "    df_new['percentage capital'] = df_new['percentage capital'].fillna(0)\n",
    "    df_new['class'] = df_new['class'].astype(int)\n",
    "    import re\n",
    "\n",
    "    def fun_starts_integer(x):\n",
    "        reg = r\"\\d+?\\s.*\"\n",
    "        pat = re.compile(reg)\n",
    "        if pat.match(x) == None:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def fun_starts_decimal(x):\n",
    "        reg = r\"\\d+\\.\\d+?\\s.*\"\n",
    "        pat = re.compile(reg)\n",
    "        if pat.match(x) == None:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    df_new['starts_integer'] = df_new['extracted_text'].apply(\n",
    "        lambda x: fun_starts_integer(x))\n",
    "    df_new['starts_decimal'] = df_new['extracted_text'].apply(\n",
    "        lambda x: fun_starts_decimal(x))\n",
    "    return df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('outputv3.csv')\n",
    "df2 = pd.read_csv('outputv3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df_final = feature_extraction(df2)\n",
    "df_final.to_csv('feature_output_final.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('feature_output_final.csv')\n",
    "df.drop(columns=df.columns[0], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['extracted_text', 'class'])\n",
    "y = df['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(\n",
    "    max_depth=9, random_state=0, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9871244635193133"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_train, clf.predict(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "plot_confusion_matrix(clf, X_test, y_test)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "percentage capital     0.387536\n",
       "words                  0.248446\n",
       "starts_integer         0.157429\n",
       "stopwords              0.089979\n",
       "endswithdot            0.075684\n",
       "starts_decimal         0.013368\n",
       "Table                  0.011194\n",
       "contains_image         0.008900\n",
       "contains percentage    0.005523\n",
       "contains_table         0.001940\n",
       "dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = pd.Series(clf.feature_importances_,\n",
    "                        index=X_train.columns).sort_values(ascending=False)\n",
    "feature_imp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was found that the feature 'contains the word section' was not important. Hence it was dropped in feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "file_name1 = \"random_forest_vfinal.pkl\"\n",
    "\n",
    "# save\n",
    "joblib.dump(clf, open(file_name1, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lines(location):\n",
    "    document = open(location, 'r')\n",
    "    doc = [x.rstrip() for x in document.readlines()]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = read_lines('output-plain-document.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Text', 'Contains Image', 'Table'])\n",
    "for element in doc:\n",
    "    if element != '':\n",
    "        df = df.append({'Text': element, 'Contains Image': int(\n",
    "            'Figure' in element), 'Table': int('Table' in element)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2.columns = ['text', 'contains_image', 'contains_table']\n",
    "df2 = df2.reindex(columns=['text', 'contains_image',\n",
    "                           'contains_table', 'extracted_text', 'class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= complete_tags(df2)\n",
    "df2.to_csv('output_txt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_txt(df):\n",
    "    df_new=df[['extracted_text','class','contains_image','contains_table']]\n",
    "    df_new.dropna(inplace=True)\n",
    "    df_new.reset_index(drop=True, inplace=True)\n",
    "    df_new['extracted_text'] = df_new['extracted_text'].str.strip()\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords  \n",
    "    df_new['words'] = df_new['extracted_text'].apply(lambda x: len(x.split()))\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df_new['stopwords'] = df_new['extracted_text'].apply(lambda x: len(set(x.split()) & stop_words))\n",
    "    df_new['endswithdot']=df_new['extracted_text'].str.endswith('.')\n",
    "    df_new['endswithdot']=df_new['endswithdot'].astype(int)\n",
    "    df_new['Table']=df_new['extracted_text'].str.contains('Table')\n",
    "    df_new['Table']=df_new['Table'].astype(int)\n",
    "    df_new['contains section']=df_new['extracted_text'].str.contains('Section')\n",
    "    df_new['contains section']=df_new['contains section'].astype(int)\n",
    "    df_new['contains percentage']=df_new['extracted_text'].str.contains('%')\n",
    "    df_new['contains percentage']=df_new['contains percentage'].astype(int)\n",
    "    df_new['Uppercase'] = df_new['extracted_text'].str.findall(r'[A-Z]').str.len()\n",
    "    df_new['Lowercase'] = df_new['extracted_text'].str.findall(r'[a-z]').str.len()\n",
    "    df_new['percentage capital']=(df_new['Uppercase']*100)/(df_new['Lowercase']+df_new['Uppercase'])\n",
    "    df_new.drop(columns=['Uppercase','Lowercase'],inplace=True)\n",
    "    df_new.dropna(inplace=True)\n",
    "    df_new['class']=df_new['class'].astype(int)\n",
    "    import re\n",
    "    def fun_starts_integer(x):\n",
    "        reg = r\"\\d+?\\s.*\"\n",
    "        pat  = re.compile(reg)\n",
    "        if pat.match(x)==None:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    def fun_starts_decimal(x):\n",
    "        reg = r\"\\d+\\.\\d+?\\s.*\"\n",
    "        pat  = re.compile(reg)\n",
    "        if pat.match(x)==None:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    df_new['starts_integer']=df_new['extracted_text'].apply(lambda x:fun_starts_integer(x))\n",
    "    df_new['starts_decimal']=df_new['extracted_text'].apply(lambda x:fun_starts_decimal(x))\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4315: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\VIGNESH S\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('output_txt.csv')\n",
    "df_final = feature_extraction_txt(df)\n",
    "df_final.to_csv('features_txt.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>class</th>\n",
       "      <th>contains_image</th>\n",
       "      <th>contains_table</th>\n",
       "      <th>words</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>endswithdot</th>\n",
       "      <th>Table</th>\n",
       "      <th>contains section</th>\n",
       "      <th>contains percentage</th>\n",
       "      <th>percentage capital</th>\n",
       "      <th>starts_integer</th>\n",
       "      <th>starts_decimal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AUSTRALIAN PRODUCT INFORMATION</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>IMFINZI?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(durvalumab)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1 \\tNAME OF THE MEDICINE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Durvalumab</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  extracted_text  class  contains_image  \\\n",
       "0           0  AUSTRALIAN PRODUCT INFORMATION      0               0   \n",
       "1           1                        IMFINZI?      1               0   \n",
       "2           2                    (durvalumab)      1               0   \n",
       "3           3        1 \\tNAME OF THE MEDICINE      0               0   \n",
       "4           4                      Durvalumab      2               0   \n",
       "\n",
       "   contains_table  words  stopwords  endswithdot  Table  contains section  \\\n",
       "0               0      3          0            0      0                 0   \n",
       "1               0      1          0            0      0                 0   \n",
       "2               0      1          0            0      0                 0   \n",
       "3               0      5          0            0      0                 0   \n",
       "4               0      1          0            0      0                 0   \n",
       "\n",
       "   contains percentage  percentage capital  starts_integer  starts_decimal  \n",
       "0                    0               100.0               0               0  \n",
       "1                    0               100.0               0               0  \n",
       "2                    0                 0.0               0               0  \n",
       "3                    0               100.0               1               0  \n",
       "4                    0                10.0               0               0  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'features_txt.csv'\n",
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt  # for data visualization purposes\n",
    "import seaborn as sns  # for statistical data visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>class</th>\n",
       "      <th>contains_image</th>\n",
       "      <th>contains_table</th>\n",
       "      <th>words</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>endswithdot</th>\n",
       "      <th>Table</th>\n",
       "      <th>contains section</th>\n",
       "      <th>contains percentage</th>\n",
       "      <th>percentage capital</th>\n",
       "      <th>starts_integer</th>\n",
       "      <th>starts_decimal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Durvalumab</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Each vial of IMFINZI concentrated solution for...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>For the full list of excipients, see Section 6.1.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sterile, preservative free, clear to opalescen...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IMFINZI (durvalumab) is indicated for the trea...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>Section updated as a consequence of the deleti...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.493506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>New ?1500 mg every 4 weeks? dosage for NSCLC h...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.634146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>?1500 mg every 4 weeks? dosage added as per CD...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.756098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>? AstraZeneca 2021</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>Doc ID-003924983 v14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>594 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        extracted_text  class  contains_image  \\\n",
       "4                                           Durvalumab      2               0   \n",
       "6    Each vial of IMFINZI concentrated solution for...      2               0   \n",
       "7    For the full list of excipients, see Section 6.1.      2               0   \n",
       "9    Sterile, preservative free, clear to opalescen...      2               0   \n",
       "13   IMFINZI (durvalumab) is indicated for the trea...      2               0   \n",
       "..                                                 ...    ...             ...   \n",
       "687  Section updated as a consequence of the deleti...      2               0   \n",
       "688  New ?1500 mg every 4 weeks? dosage for NSCLC h...      2               0   \n",
       "689  ?1500 mg every 4 weeks? dosage added as per CD...      2               0   \n",
       "690                                 ? AstraZeneca 2021      2               0   \n",
       "691                               Doc ID-003924983 v14      2               0   \n",
       "\n",
       "     contains_table  words  stopwords  endswithdot  Table  contains section  \\\n",
       "4                 0      1          0            0      0                 0   \n",
       "6                 0     17          3            1      0                 0   \n",
       "7                 0      9          2            1      0                 1   \n",
       "9                 0     19          4            1      0                 0   \n",
       "13                0     23          7            1      0                 0   \n",
       "..              ...    ...        ...          ...    ...               ...   \n",
       "687               0     14          4            1      0                 1   \n",
       "688               0     12          3            1      0                 0   \n",
       "689               0     15          1            1      0                 0   \n",
       "690               0      3          0            0      0                 0   \n",
       "691               0      3          0            0      0                 0   \n",
       "\n",
       "     contains percentage  percentage capital  starts_integer  starts_decimal  \n",
       "4                      0           10.000000               0               0  \n",
       "6                      0           10.000000               0               0  \n",
       "7                      0            5.555556               0               0  \n",
       "9                      0            0.806452               0               0  \n",
       "13                     0            7.500000               0               0  \n",
       "..                   ...                 ...             ...             ...  \n",
       "687                    0            6.493506               0               0  \n",
       "688                    0           14.634146               0               0  \n",
       "689                    0            9.756098               0               0  \n",
       "690                    0           18.181818               0               0  \n",
       "691                    0           50.000000               0               0  \n",
       "\n",
       "[594 rows x 13 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df['contains section']!=0]\n",
    "df[df['class'] == 2]\n",
    "# sum(df['contains section']!=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of section class in target feature is 85.84%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "df['class'].value_counts().plot(kind='bar')\n",
    "plt.xlabel('class'), plt.ylabel('Count'), plt.xticks(rotation='horizontal')\n",
    "plt.title(\"Count vs Class\")\n",
    "print(\"The percentage of section class in target feature is {0:.2f}%\".format(\n",
    "    df['class'].value_counts()[2]/sum(df['class'].value_counts())*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    594\n",
       "1     87\n",
       "0     11\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['contains_table', 'extracted_text', 'class'], axis=1)\n",
    "y = df['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    415\n",
       "1     61\n",
       "0      8\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    179\n",
       "1     26\n",
       "0      3\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM with default hyperparameters\n",
    "Default hyperparameter means C = 1.0, kernel = rbf and gamma = auto among other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with default hyperparameters: 0.8606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# import metrics to compute accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "# instantiate classifier with default hyperparameters\n",
    "svc = SVC(random_state=42)\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train, y_train)\n",
    "# make predictions on test set\n",
    "y_pred = svc.predict(X_test)\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(\n",
    "    accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM with rbf kernel, C=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with rbf kernel and C=100.0 : 0.8894\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with rbf kernel and C=100\n",
    "svc = SVC(C=100.0, random_state=42)\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train, y_train)\n",
    "# make predictions on test set\n",
    "y_pred = svc.predict(X_test)\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(\n",
    "    accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': 42,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.get_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM with rbf kernel, C=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with rbf kernel and C=100.0 : 0.8894\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with rbf kernel and C=1000\n",
    "svc = SVC(C=1000.0, random_state=42)\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train, y_train)\n",
    "# make predictions on test set\n",
    "y_pred = svc.predict(X_test)\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(\n",
    "    accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SVM with linear kernel and C=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with linear kernel and C=1.0 : 0.8894\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with linear kernel and C=1.0\n",
    "linear_svc = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "# fit classifier to training set\n",
    "linear_svc.fit(X_train, y_train)\n",
    "# make predictions on test set\n",
    "y_pred_test = linear_svc.predict(X_test)\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(\n",
    "    accuracy_score(y_test, y_pred_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SVM with linear kernel and C=100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with linear kernel and C=100.0 : 0.8894\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with linear kernel and C=100.0\n",
    "linear_svc = SVC(kernel='linear', C=100.0, random_state=42)\n",
    "# fit classifier to training set\n",
    "linear_svc.fit(X_train, y_train)\n",
    "# make predictions on test set\n",
    "y_pred_test = linear_svc.predict(X_test)\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with linear kernel and C=100.0 : {0:0.4f}'. format(\n",
    "    accuracy_score(y_test, y_pred_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'linear',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': 42,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svc.get_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "svm_param_grid = {'C': np.logspace(1, 7, num=30, base=2), 'gamma': [\n",
    "    0.1, 0.01, 0.001, 1], \"kernel\": [\"rbf\", \"linear\"]}\n",
    "# svm_param_grid = {'C': np.logspace(3,6,num=20,base = 2)}\n",
    "\n",
    "# Create SVM grid search classifier\n",
    "clf = SVC(random_state=42)\n",
    "svm_grid = GridSearchCV(clf, svm_param_grid, cv=4, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Train the classifier\n",
    "svm_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\\n\", svm_grid.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", svm_grid.best_score_)\n",
    "\n",
    "# Select best svc\n",
    "best_svc = svm_grid.best_estimator_\n",
    "\n",
    "# Make predictions using the optimised parameters\n",
    "svm_pred = best_svc.predict(X_test)\n",
    "\n",
    "print('SVM accuracy:', round(accuracy_score(y_test, svm_pred), 3))\n",
    "cm_svm = confusion_matrix(y_test, svm_pred)\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm_svm, annot=True, ax=ax, fmt='g', cmap='Greens')\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('SVM Confusion Matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.DataFrame(svm_grid.cv_results_)\n",
    "dfr[dfr['rank_test_score'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(svm_grid, 'svm_grid_txt.pkl')\n",
    "joblib.dump(svm_grid.best_estimator_, 'best_svc_txt.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = best_svc.predict(X)\n",
    "X['extracted_text'] = df['extracted_text']\n",
    "X['True_class'] = df['class']\n",
    "X['Predicted_class'] = y_predicted\n",
    "X.to_csv('Predictions_txt_svm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['extracted_text', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d19b357432ce88e55d85637f355d8036bdbcd8293d5e1eb53161316a36fbb1f8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
